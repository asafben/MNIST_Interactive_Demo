# MNIST_Interactive_Demo
Learning MNIST using the LeNet architecture.  
Tweaking with different parameters:  
* GD vs. SGD
* Batch size.
* Learning rate.
* Learning algorithm - i.e AdamOptimizer, AdagradOptimizer.
* Activation function - i.e ReLU.
* Initialization of weights.
* Neural network architecture. 
